% !TEX root = ../Thesis.tex
\chapter{Introduction}
\label{c:intro}

For the past decade, cloud computing has become a crucial and central part in the industry \cite{claremont:2005}.
This technological advancement in infrastructure provisioning allows companies to obtain 
software as well as hardware resources to compose their entire data center virtually in the cloud.
Without having to invest in expensive hardware and real estate they can now avoid maintaining 
their computing resources solely on premise. These providers usually manage different distributed data centers 
across the globe and provide private or shared access on resources according to their 
Service Level Agreement (SLA). Such guarantees in quality-of-service (QoS) usually 
include elastic up- and down-scaling of resources and a high degree of availability,
which is achieved by replicating data throughout different regions \cite{brinkmann:2015} \cite{terry:2013}. 

Ever since the rise of the \emph{Big Data} era, these providers are faced with continuous
and rapidly growing heterogeneous datasets. These are accompanied by widely varying requirements 
and characteristics for data driven applications. This increased the need to leverage custom-tailored 
database systems to gain meaningful insights on their data as quickly as possible.
To efficiently process and extract relevant information out of these data silos new systems
have emerged. These aim to provide a solution for the new demands on varying workloads 
and ever-growing data sources.
Such novel Polystore systems combine several distributed physical data engines to enable various
new possibilities and provide the best response time for every use case by exploiting
the key benefits of each engine \cite{stonebraker:2005} \cite{polypheny2020}. Although these data management systems are inherently
built to process heterogeneous data with high throughput, the amount of produced data
still grows continuously.
Therefore, the importance to efficiently access the right data is crucial
for organizations to stay economical and competitive. Cloud providers which offer such systems consequently 
need reliable functionality to manage these large volumes of data. Otherwise, they would waste useful 
computations and time when users try to retrieve relevant data items ~\cite{levandowski2013}.
To comply with their QoS requirements and sufficiently provide acceptable access times for their services, 
they have come up with data freshness strategies as an essential part of data management in a
distributed setup. 
The freshness in such cases reflects how current and up-to-date a specific data item is.
Since not all applications pursue similar goals, they often require different levels of freshness.
These levels can be used to identify a well-suited location to retrieve the desired data object. 
This consequently mitigates the need to always update every existing data replica to the most recent state.
Changes can now rather be deferred, until they are processable by the underlying system again.
Such delayed updates now allow for a much higher throughput and increased performance in scenarios were also slightly 
outdated data is acceptable.


\todoMissing{TCO because even if highly replicated systems we might only use the secondary nodes in case of failure situations.}

\todoMissing{with Polyphenys lazy replication we could limit the primary update to fast OLTP driven stores and lazily updating other stores}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Goal?}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Contribution}
The contribution of this thesis is fivefold. First, we identify and define necessary requirements to establish freshness-awareness in general.
Second, we outline and propose various possibilities to enable freshness-awareness. Foruth, we introduce a query extension to allow the specification
of tolerated and desirable freshness levels on various metrics. Fifth, 

To identify necessary requirements to implemented and design possible 
freshness variations in a polystore system. Several aspects of previous published research work is compared and considered when adapting it to polystore systems.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Outline}
This thesis is structured as follows:
Chapter \ref{c:motivation} motivates and illustrates the benefits of a freshness-aware data management approach and how it would impact a given scenario.
In Chapter \ref{c:related} the foundations and concepts of data freshness characteristics and requirements are presented.
We give an overview over the current state of research in the field of data freshness. 
Chapter \ref{c:Foundation} illustrates existing fundamental concepts in the context of distributed data management systems. 
The system architecture of the polystore: Polypheny-DB is described in Chapter \ref{c:architecture}.
Chapter \ref{c:concept} describes the necessary functional requirements, necessary to introduce the notion of freshness inside a polystore system. Additionally, 
it proposes and discusses possible approaches how to implement them in Polypheny-DB. 
The implementation of the freshness notion as well as coexisting building blocks are described in Chapter \ref{c:implementation}.
While Chapter \ref{c:evaluation} focuses on possibilities how to ensure correctness and measure the performance of an implementation, including all necessary prerequisites.
Finally, Chapter \ref{c:conclusion} concludes the thesis by summarizing the individual contributions according to the proposed
implementations and gives an outlook to future work and possible extensions.


