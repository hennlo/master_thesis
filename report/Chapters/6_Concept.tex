% !TEX root = ../Thesis.tex
\chapter{Concept}
\label{c:concept}

\todoMissing{Check that concept is not bound to any implementation}

In this chapter we will define all functional requirements, necessary to establish freshness-aware data management.
We will therefore discuss the contents of \ref{c:related} and propose concrete solutions how these approaches and techniques can be applied to polystore system.
Hence, this chapter is separated into several sections were each represents a necessary building block to provide the notion of data freshness in Polypheny-DB.


\section{Functional Requirements}
Except the obvious existence of multiple versions per data object (see \ref{sec:data_replicas}), there are several prerequisites and requirements to establish freshness-awareness. 

Essentially we have to think about how we want to express freshness(see \ref{express}), find a suitable metric to measure it (see \ref{sec:metric})
and provide users a possibility to formulate an acceptable level of freshness. Based on these fundamentals we need to consider how update transactions 
can be decoupled and deferred, how replicas will
be refreshed \ref{sec:replication_strategy} while ensuring the consistency \ref{consistency_concept} of the system and how to enable the routing to identify freshness levels to speed up read-only operations. 


as described in Section \ref{sec:part}, since read-only queries typically benefit directly from data partitioning, they are suitable candidates to base our freshness awareness on.
Therefore, we propose to define outdatedness on the state of a specific partition placement.
Although the entire data placement, could be labeled as outdated or rather receive updates lazily, some of 
these partitions could already be up-to-date again, while others still remain outdated.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Data Replicas}
\label{sec:data_replicas}

One of the main requirements of data freshness is the necessity and existence of different versions that can receive outdated data. 
Only with these versions we are even able to compare their state and define a freshness for a given replica.

As the name suggests a multi-version database would be ideal and the obvious choice for such an approach.
These databases will automatically generate a new version for a data object on each modification.
Due to their properties we would immediately have the information on the validity-interval of the version, its update time as well as older and newer versions.
This would directly allow us to utilize these versions on freshness-related queries. But, it would also imply the utilization of MVCC.
However, Polypheny-DB currently only supports SS2PL for its concurrency control. 

Additionally, there are a lot of trade-offs to consider when using MVCC as previously stated in \ref{sec:concurrency_control}.
For one, it has a large data footprint which is already inherently larger in a polystore system, given the redundant data storage.
Furthermore, since all transactions are handled within the polystore layer we need a correct and serializable execution order on all stores. Hence, we need to provide
a more rigorous and uniform schedule on all stores, which is not directly provided by MVCC.
That is why we stick with SS2PL and refrain from using the automatic versioning provided by a multi-version database.\\

However, since we are in a polystore environment and want to reduce locking situations by decoupling primary updates from secondary transactions,
we can use lazy replication, which by definition creates multiple versions when deferring the update propagation to secondaries.
This approach is discussed in more detail in section \ref{sec:replication}.\\
 


\todoMissing{However, we want to include primary nodes for reads as well }



As already discussed in \ref{r:strategies} it is crucial to define and assign roles to loosen the locking situation on nodes
to minimize update times over all.
The related work clearly separated between primary-update nodes and read-only nodes, where 
read-only nodes cannot be directly updated by the user and will only receive refresh updates internally by the primary nodes.

Since we always need a foundation for all freshness-related comparisons we will need at least one up-to-date node. 
This replica should contain relevant information to illustrate the deviation from another possibly outdated replica.
To achieve this we need to be able to classify existing Data Placements into specific groups or roles.
Naively these could be \emph{up-to-date} and \emph{outdated}.\\
On the basis of these roles we are then able to decide which replicas to consider for which use case.
Alongside the idea of a polystore system, where each underlying engine has its own purpose, we can directly apply these roles 
based on the provided use case. E.g. label Data Placements as up-to-date that support highly transactional workload and will therefore be considered for every update.
And configure replicas as outdated, when they are rather suitable for analytical queries.
This immediately harvests the benefits of the encompassed stores. \\



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section{Data Freshness}
\label{express}

As discussed in \ref{r:express_freshness}, freshness can be expressed via several indications.
While freshness extractions on value-based divergence is only really suitable for numerical values,
to calculate the percentage of deviations from the base item, time-based freshness can be applied to arbitrary types and can therefore be used 
in a more general notion. 
Such time-bound constraints allow utilizing timestamps as well as the usage of freshness indexes when referring to a desired level of freshness. 
Although a timestamp can be used more intuitively, an index is abstract and can therefore be generally applied without having to specify an absolute time dependency.
Because the perception of freshness is rather subjective and depends on the use case, the time-based constraints are often not sufficient for very frequently updated replicas.
The accuracy would differ greatly when, it has received an update within the last minute and might be considered fresh, but the entire table could have been 
changed by now. This would rather reduce the freshness to a simple version comparison and allow questions such as, "if it exists, how did the entity look like roughly one minute ago".
Admitting that this might be desirable for some use cases we want to extend this notion by allowing to consider deviations from the primary copy as well. 

Hence, we propose that users can specify their tolerated level of freshness in a variety of ways. These constraints can be roughly differentiated into
timeliness and deviations from the primary copy. 

We therefore want to provide the possibility to let users request their accepted level of freshness as an attachment to the query language. 
This can be achieved by extending the query functionality of Polypheny-DB.

Such constraints can either be formulated by providing a timestamp to implicitly give an accepted lower bound on an absolute time.
Additionally, time delays such as \textit{"Last 30 minutes"} can be specified to request a relative freshness level.
Finally, by directly requesting a desired level of freshness defined as a percentage value, meaning a value of 70\% would tolerate data objects
with a flexible accuracy of 30\% outdated data corresponding to the time since the primary copy has been updated.
However, internally all specifications are converted into freshness indexes since they are independent of any time window and can be constructed, compared and applied 
without any restrictive dependencies.\\

Moreover, to improve the user experience the query tree paths should be extended to specify which level of freshness was requested and with which level it was 
ultimately fulfilled. Furthermore, for successfully executed queries that considered some kind of freshness it shall be added in the SQL response that is has been 
executed by means of a specific freshness level.
In such a way a user can not only steer its desire but is also informed whether the request could be fulfilled.

Whereas the modification deviation is the delta of operations that still need to be applied to a secondary node in order to become up-to-date in regard to the primary. 




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section{Freshness Metrics}
\label{sec:metric}



As described in section \ref{sec:definition}, there is no unified definition of data freshness or common freshness metrics.
These rather depend on specific use cases and system requirements.
\tocless\subsection{Time-based constraints}
\subsection{Absolute Timestamp}
\subsection{Absolute-Delay - From Current Time}
Both reconstruct a timestamp that enacts as a lower bound of acceptable placements.
This can be used as a filter to check for each candidate placement that it is fresher or respectively has received a state where its commit time is newer 
than the lower bound. If not the placement is removed from the possibly candidates. 


\tocless\subsection{Replica-deviations}

\subsection{Relative-Delay - Deviation From Eager Replica}
Although also based on a time difference it checks relative to the specified time delay on the eager  replica how far away is the lazy replica.

\subsection{Data Accuracy - Modification - Deviation From Eager Replica}
This can also be used in referential integrity when joining multiple table entities.
We can use the joint number of modifications and compare it against the current number of update transactions to give a joint accumulation.


\subsection{Data Accuracy - Time -  Deviation From Eager Replica}

Both construct an index or percentage of "hit ratio"


\begin{description}
    \item [Absolute Timestamp]  fr
    \item [Dela] fd
\end{description}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Replication}
\label{sec:replication}

\todoMissing{Fill}
The system can implement each of these cases in various ways; however, each implementation comes with a consistency/latency trade-off.



\todoMissing{asyncronous immediate, adhoc, load-aware}

\subsection{Replication Strategies}
\label{sec:replication_strategy}
Since data freshness occurs as a side effect of using lazy replication and can therefore already
be used as a consequence of saving workload when not needing to update every replica eagerly.
As suggested in \ref{r:replication} there exist several techniques how outdated nodes can be updated lazyily in the context of freshness.
Most of these presented distributed architectures follow a primary-copy approach for master-driven replication to all their secondary replicas.
This eases the the control and flow of data. Although in the proposed works some systems allowed to access read-only copies directly
with Polypheny-DB we always have a single point of entry which can vaguely be compared as the poly-layer acting as a master node
when distributing or even routing queries. Hence Polypheny acts as the master anyway. However since any requests have to pass through the poly-layer
we have full control how and where queries need to be routed to allowing us to selectively route read-operations to outdated and up-to-date stores alike.
This enables Polypheny-DB to take full control how different levels of data freshness are being accessed.

With this abstraction layer on top of the stores we can leverage the DBMS to act as a coordination service allowing us to loosen the eager replications and 
locking mechanisms to be restricted to the primary nodes only. Currently, one has to wait until an update is persisted everywhere and are therefore
dependened on slowest performing store.
To mitigate this behaviour we want to decouple the commonly used update transactions and logically divide it into a total of three separate transactions types
to allow deferred refreshments of objects.
\begin{itemize}
    \item \textbf{Update transaction}: Consequently are write operations that are targeted on primary placements only.
    \item \textbf{Propagation transaction}: Belong to a refresh operation updating the data freshness of an outdated secondary node which is 
    executed automatically by the system.
    \item \textbf{Refresh transaction}: A propagation transaction which is manually triggered by a user to refresh the data on an arbitrary outdated node.
\end{itemize}

Allthough, logically being used differently they are technically executed with the same capabilities and only really separate in terms of locking.
They are rather used as a clear indication on which part of the process is referred.

These changes will also have an impact on the partition distribution constraints. For vertically and horizontally partitioned 
entities this means that all constraints on the number of available column-placements can only be considered for primary update stores. Otherwise, this could harm
the consistency of the system. For nodes labeled as outdated any variation is possible.

\subsection{Update Propagation}
We have several possibilities how to handle and propagate the updates.
Since every write-operation needs to go through Polypheny, we can easily keep track which operations have been applied to the primary server and when 
they need to be applied to the secondaries. Essentially every possible solution needs some form of queue to store updates that still need to be executed 
on secondaries. For correct serializability it is sufficient to store the commit timestamp of the update transaction with each queue item. This imposes a natural
execution order of any item in the queue to be delivered to the secondaries.
We propose the following approaches: \\

\textbf{CDC (Change Data Capture)}\\
We can implement the notion of a shadow table which is filled by trigger on the base table.
As soon as the base table gets modified by an update transaction any changes applied are stored and consequently tracked.
Accompanied by a commit-timestamp its content is then used inside propagation transactions to refresh outdated placements.
Once placements are updated the propagated entries inside the shadow table are deleted. 
This has the advantage that we can utilize a common datastructure in Polypheny out-of-the-box without having to implement any further activities.
It is persisted and available after a downtime which ensures the recoverability of the system.
However since this results is generating several statements that essentially has to traverse the entire system in order to be executed this could lead to 
large overhead in the system which could impact the performance as well as requiring more resources.
Furthermore, since this is an updatable table the implemented locking mechanisms has to be applied as well. This excessive accessing however could result in high 
locking situations and therefore again impact the update time after all.\\

\textbf{Internal structure}\\
Another possibility would be to handle this approach entirely with internal structures.
For example with the implementation of a MOM (Message Oriented Middleware) between the poly-layer and available adapters. The initial update transactions can append 
the changes into a persistent queue. This queue can then be asynchronously queried using a pull-based approach on adapter site to apply all changes necessary for them. \\

\textbf{Internal Partitions} \\
Another propositions would be the usage of background processing together with physical partitions. Although, they were originally intended to serve the horizontal partition 
use case they are internally configured to represent a physical table. Partitions could be extended to be used as general system internals
which are accompanied by an update-timestamp that represents the last time the partition has been updated, this could include the Age-of-Information as well as 
the Age-of-Synchronization. Furthermore, since partitions logically belong to partition groups described in \ref{express} we can easily identify which partitions are considered to be 
outdated or should always be up-to-date. With these information we could even use the existing capabilities of the \emph{Partition Manager} which uses the notion of 
partition-qualifiers to identify required levels of freshness.

For every update-transaction the eager replication is loosend to only consider the primary partitions for updates.
For the refresh operation itself we can utilize the \emph{Data Migrator} to extract the relevant data via an accumulated select-statement on the primary placements.
Additionally, to further decouple the data refreshment a hidden shadow partition can be created for this purpose. In that way writes on the primary copy as well as the 
currently existing outdated placements can still be executed while the outdated placement gets refreshed in the background. Once the data migration process has finished, 
we only need to logically apply a \emph{Refresh-Lock} to ensure the overall consistency. During the short time the outdated-site is locked the old placement is dropped and 
the hidden shadow partition is officially being activated. Since this only really requires one select on the primary site, write-operations can still take place, reducing
locks to a minimum. Even during the time the refresh-lock is active the benefits of the poly-layer comes in to play which enables the system to choose to 
route read-operations to primary servers as well.\\


\textbf{View Materialization}:\\
Along the idea of internal partitions materialization could help reduce the number of statements necessary to create new levels of freshness.
Since materialized views are considered to be snapshots of data objects, anytime a propagation or refresh operation is being executed a new materialized view is 
generated on basis of the up-to-date placement.
This would ommit replication operations entirely hence no bookkeeping of the queued updates would be necessary. The only needed reference would be the new timestamp
to calculate the freshness index.

As with the handling of internal partitions this can also be done entirely in the background. This limits the locking time to a minimum and is therefore only really 
necessary when switching the outdated with a refreshed view.
Although, one of the biggest downsides of materialization is the large additional resource consumption on storage, it can be neglected for polystore systems, since they are
inherently distributed and would otherwise store the entire content of the table. Therefore, it would even slightly reduce the data footprint on outdated placements.







\subsection{Refresh strategies}
As already stated above, there are essentially three ways to update a secondary node. 
For the automatic execution of propagation transactions a periodic execution has several downsides hence we propose to schedule
refreshment on the basis of the load on the outdated placements. Therefore, we will extend the adapter of the underlying stores to gather metrics on current workload
average response times in order to enable the poly-layer to decide based on this metrics when it is suitable to carry out a propagation-transaction.


Since it might be possible that a user may consider refreshing a placement manually, we have proposed refresh transactions. With this a user has the possibility to refresh
any replicas which are classified as outdated to a specific freshness level.
\begin{verbatim}
ALTER TABLE dummy REFRESH PLACEMENT ON STORE outdated_store 
UNTIL <TIMESTAMP>;
\end{verbatim}
Without any specification the placements shall be updated to the most recent state of the up-to-date version:
\begin{verbatim}
ALTER TABLE dummy REFRESH PLACEMENT ON STORE outdated_store;
\end{verbatim}

For this operation only freshness levels greater than the current local freshness level can be considered.
Furthermore, this should also provide the possibility to refresh all placements of an object.
\begin{verbatim}
ALTER TABLE dummy REFRESH ALL PLACEMENTS;
\end{verbatim}

Although such refresh-transactions can be executed on any placement, it will have no effect on primaries and simply omit their execution. 




\subsection{Identify stale data}
\label{stale}

A prerequisite for the automatic execution of propagtion transactions is the identification of stale and outdated placements.
Although a trivial option would be to use the roles described in \ref{roles} and periodically gather all labeled placements, this would not scale much
considering a large amount of tables with at least one additional replica per table.\\

One proposition would be after every update transaction has commited to immediately inform dedicated notification services which will instantly trigger 
a load analysis on stores to be replicated. A sligthly different approach would be a central gossiping service as an adapter extension that gathers store metrics 
and declares them as idle, or loaded. With such a mechanism the notification service which received the information to update stores would not start querying a server
again and can directly utilize the pre-gathered metrics and choose to execute the update or defer it again.\\

Another approach to identify and update stale placements would be the idea to use update-on-read. Everytime a node flaged as outdated is used to serve a 
read-operation the level of freshness can be checked. If identified as outdated this could then trigger any of the propagation transactions proposed in 
\ref{r:strategies}. This would completely omit periodic background scheduling and would shorten processing time.\\

However, for both cases in terms of the resulting refresh rate we still have to consider if the change data becomes too large the refreshes tend to take longer.
So countermeasures have to be defined to minimize errors or downtimes.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section{Transactional guarantees - Locking - Isolation Level}
\label{consistency}

To support the overall consistency of the system we have to ensure that all updates are correctly serialized and applied to the system.

Polypheny for one ensures global atomicty by using the two-phase commit (2PC) protocol and for correct isolation treatment
strong strict to phase locking (SS2PL). Currently, all placements are eagerly updated and locked whenever a write-operation is executed.
We need to loosen that constraints to increase update times and still ensure all transactional guarantees. The locking mechanism should therefore 
now only consider primary nodes. In that way we still can utilize secondaries with slightly outdated data for reads.\\

To ensure that the overall correctness of the system is maintained we will restrict the solution to allow freshness related parameters solely
for read-only transactions. For every update-transaction which considers freshness of any kind, consistency cannot be guaranteed since we might read outdated data
and use this data to write into another table. Therefore, we propose to enrich  the transactional context of Polypheny with a flag that states if any read-operation 
considers freshness. If this is the case, the update-transactions needs to be aborted.\\


Another important point to note is the referential integrity of outdated tables. We already ensured that outdated data cannot be used within update-transactions to 
ensure consistency and therefore guarantee correctness. However, for read-only transactions it should still be possible to join any tables while considering 
a desired level of freshness. 
Since it is rather complex and would result in refactoring the core of Polypheny-DBs, we currently refrain from supporting MVCC.
Hence, it might occur that cumulative reads on multiple objects might return incomplete results, since a specified freshness
level can be entirely different on two tables which makes it hard to even compare freshness levels among different objects. However since a user is willing to access 
stale data anyway this is a known risk and thus can be accepted.\\

Finally, as introduced in \ref{replication} the \emph{Refresh-Lock} is a newly introduced lock which holds the same characteristics as a regular lock on an object.
However, it shall only be applied whenever a refresh operation is currently in place. This way the routing mechanism can avoid sending any queries to that placement
for reads or a new refresh operation, which might have been triggered manually by an user.

To ensure the correct execution of refresh operations every placement that is outdated will receive an independent propagation- or refresh-transaction.
The serialization order of the updates to be executed is the commit order of the initial write transaction.
These can also be refreshed and updated independently which not only again reduces the total update time but also eases rollback scenarios.
Otherwise, we might need to define complex countermeasures to undo certain refreshes if one store was already refreshed but another has failed.

\todoMissing{List what building blocks are necessary to compose a freshness concept. Check if needed as separate section}

\todo{Resort}
The locking is done logically within the polystore layer and locks the entire table.
Since we want to establish the freshness comparison ob objects based on the Data Placement respectively each individual partition placement, the locking mechanism
needs to be adapted to allow locking not only on table-level but rather on a partition level. 

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Freshness-aware Read Access}

With the description of \ref{express} how to explicitly express freshness, users have the ability to hint or even guide the routing process to select placements 
based on their desired freshness.\\
Users can choose to specify any tolerated level of freshness. The routing process analyzes this specification and gathers all placements which fulfil the necessary 
requirements by preferring secondary nodes labeled as outdated.
In case no secondary node can fulfil the request a primary placement is used to serve the query since they are not exclusive to receive updates such in other systems,
consequently utilizing all source available to the system.
Since only few systems presented in \ref{r:read} provided this functionality the routing process can be extended to support load balancing. 
With the proposed adapter background analysis the router can observe if any selected placement might be overloaded and therefore chooses to route 
queries to a different available location. \\



For the overall freshness guidance an extension of PolySQL is necessary.
Along the description in \ref{express} users can choose to select any of the specifications to guide the system.
\begin{verbatim}
SELECT * FROM dummy 
[ WITH FRESHNESS [ <TIMESTAMP> | <DELAY> | <PERCENTAGE> ] ];
\end{verbatim}
As an extension we also propose to omit the specifications entirely and only state to the system that any freshness level is acceptable or the system central
configured default, to further speed up queries.



As mentioned in \ref{consistency} since update transactions don't allow any usage of freshness metrics to ensure consistency, solely read-only transactions are allowed.
Hence, for read-operations on outdated nodes and data, locks can be omitted entirely since you will read stale data anyway.
We therefore only have to validate that no refresh-lock is currently in place.





%\section{Policies}
\label{sec:polcies}

According to the idea, to generally relax consistency or allow a fine grained way of letting data owners decide what kind of consistency shall be desired for their object. 
Since freshness can be considered a trade-off between availability and consistency it is only fair to let users decide which level of consistency to enforce and 
how the freshness should be handled. We therefore propose the notion of policies to guide the system.
Policies are essentially intentions and desired states how the system should behave in various situations. 
The system can apply them when manual or automatic system maintenance is performed.
They shall therefore be introduced for any kind of configurable behaviour to allow any custom tailored behaviour. \\

Policies can be inherented and applied to any kind of object. When applied to a schema all entities inherent that polcies.
However, a different kind of policy with the same type can be applied to an entity overriding the one inherented by the parent.
Policies are about background processing how metadata and constraints on different objects are enforced. 
They provide a lightweight version of UDFs (User-Defined-Functions) to build custom-tailored behaviours into the system.
Other than the central configuration which is used to define core system behaviours. 
Such policies can be defined as:\\


\textbf{Consistency Policies}\\
Provide a notion of tuneable consistency, where users should be able to decide which levels to fulfill.
In such a case an administrator could choose to define how many primary replicas an object should always contain.
This would directly impact the constraints on the table restricting users to remove more placements than defined by that policy.\\


\textbf{Freshness Policies}\\
Can be utilized to define behaviour on freshness related actions. As \cite{fekete:2018} stated it is crucial to define how far a replica can diverge from the true
and up-to-date value before a refresh transaction has to be critically executed.
Additionally, we could use these types of policies to let object owners define how their data shall be identified and consequently updates are propagated.
In such a way the system would stay customizable and would allow any methods discussed in \ref{stale} to be used dependent on the use case.
Considering how refreshes are triggered one policy for example might has chosen to defer a propagation transaction entirely hence it won't try again and
essentially waits for another chance when a new update-transaction is being executed and will trigger the service again. Another policy could suit other use cases better 
and assist by constantly querying the storage's performance metrics to decide if an update should be executed.\\

Due to the inherent heterogenous nature of the polystore systems itself, use cases may widely vary. Hence, in gerneal there is no need to impose a 
general notion of freshness that is valid for all applications. Some might consider using CDC, while other prefer a partition approach or materialized views.
However, with policies these can all be implemented.\\


%\subsection{Policy usage}

Since applications that are being served by polystores are very different to each other, they might have different requirements. 
Therefore, different object types shall be supported.

A policy shall generally be created inside a database.
\begin{verbatim}
CREATE POLICY policy_name as <configuration>;
\end{verbatim}

These policies can then be added to any object.
\begin{verbatim}
ALTER TABLE dummy ADD POLICY policy_name;
\end{verbatim}

Users should always be able to list information on all applied policies on any object.
\begin{verbatim}
SHOW POLICIES ON (DATABASE | SCHEMA | TABLE ) object_name;
\end{verbatim}


Furthermore they should be able to view the content of any policy: 
\begin{verbatim}
DESCRIBE POLICIY policy_name ON (DATABASE | SCHEMA | TABLE ) object_name; 
\end{verbatim}

To complement the idea of policies we also need a central \emph{Policy Manager} which ensures that the specified intentions are ensured.
The manager shall be added as an additional central component and acts as a verification layer whenever meta information on objects will change.




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\section{Consistency}
\label{sec:consistency_concept}
Move from Strong consistency to eventual consistency 
have a loose form of consistency constraints that we need to comply with, in order to still provide response times while sacrificing consistency.

In general two requirements can be defined that have to be fulfilled to
guarantee correctness in respect of freshness. For one, transactions that refresh stores need to be executed on all read-only nodes in the same serialization order as the 
original update transaction. Secondly all queries of a read transaction must access data with the same freshness. \todo{Cite}


\todoMissing{Introduce constraints on freshness and DML operations within the same transaction}

\todoMissing{Add this to requirements when talking about what is needed to provide freshness-aware data management}
This is certainly we still have to comply with the acid properties. 

\section{Placement constraints}