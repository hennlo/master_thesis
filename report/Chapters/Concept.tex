% !TEX root = ../Thesis.tex
\chapter{Concept}
\label{c:concept}

This chapter is separated into several sections were each represents a necessary building block to provide the notion of data fresh in Polypheny-DB.
These blocks are compared and discussed to the implementations presented in \ref{c:related} to propose approaches how such techniques could be applied to polystore
systems. Essentially we have to think about how we want to express freshness, find a suitable metric to measure it and provide users a possibility to formulate 
an acceptable level of freshness. Based on these fundamentals we need to consider how update transactions can be decoupled and deferred, how replicas will
be refreshed while ensuring the consistency of the system and how to enable the routing to identify freshness levels to speed up read-only operations. 



\section{ How to express freshness}
\label{express}

As discussed in \ref{r:express_freshness}, freshness can be expressed via several indications.
Although we have described a number of domains only the time-bound constraints will be pursuit further. 
While freshness extractions on value-based divergence is only really suitable for numerical values
to calculate the percentage of deviations from the base item, time-based freshness can be applied to arbitrary types and can therefore be used 
in a more general notion. 
Such time-bound constraints allow to utilize timestamps as well as the usage of freshness indexes when referring to a desired level of freshness. 
Although a timestamp can be used more intuitively, an index is abstract and can therefore be generally applied without having to specify an absolute time dependency.

Hence, we propose that users can specify their tolerated level of freshness in a variety of ways. For one we want to provide the possibility to let users 
request their accepted level of freshness as an attachment to the query language. This can be achieved by extending the query functionality of Polypheny-DB.
Such constraints can either be formulated by providing a timestamp to implicitly give an accepted lower bound on an absolute time.
Additionally, time delays such as \textit{"Last 30 minutes"} can be specified to request a relative freshness level.
Finally, by directly requesting a desired level of freshness defined as a percentage value, meaning a value of 70\% would tolerate data objects
with a flexible accuracy of 30\% outdated data corresponding to the time since the primary copy has been updated.
However, internally all specifications are converted into freshness indexes since they are independent of any time window and can be constructed, compared and applied 
without any restrictive dependencies.\\

Moreover, to improve the user experience we consider to enrich the query tree paths to specify which level of freshness was requested and with which level it was 
ultimately fulfilled. Furthermore, for successfully executed queries that considered some kind of freshness it shall be added in the SQL response that is has been 
executed by means of a specific freshness level.
In such a way a user can not only steer its desire but is also informed whether the request could be fulfilled.




\section{ Replication Roles }
\label{roles}

As already discussed in the implementations in \ref{r:strategies} it is crucial to define and assign roles to loosen the locking situation on nodes
to minimize update times over all. The related work clearly separated between primary-update nodes and read-only nodes, where 
read-only nodes cannot be directly updated by the user and will only receive refresh updates internally by the primary nodes.
Therefore, these are the only nodes used for read-operations. 
However, we want to include primary nodes for reads as well and therefore propose the naming-convention in respect of the desired state as \emph{up-to-date nodes} for primaries
and \emph{outdated-nodes} referring to any secondary node. \\
With the introduced changes to internal partitioning described in \cite{hennemann_2021}, we now have the possibility to utilize the notion of \emph{Partition Groups}
to label stores with desired state respectively their roles.  
When deciding to use freshness on an object, administrators should be able to define how many replication tiers they want to have in a particular setup.
The minimum requirement is always a complete primary up-to-date node, either as a full placement or composed out of several vertical partitions and one outdated node.  
However, to support a multi-tier approach as \cite{voicu:2010}, outdated nodes can occur multiple times and can hold different levels of freshness with any number of vertically partitioned
placements. Therefore, a suitable mechanism has to be introduced which enables the definition of replication orders and paths. This could then be used to 
intuitively have placements at different freshness levels resulting in tertiary adapters only being updated by secondaries.\\







\section{Replication}
\label{replication}
Since data freshness occurs as a side effect of using lazy replication and can therefore already
be used as a consequence of saving workload when not needing to update every replica eagerly.
As suggested in \ref{r:replication} there exist several techniques how outdated nodes can be updated lazyily in the context of freshness.
Most of these presented distributed architectures follow a primary-copy approach for master-driven replication to all their secondary replicas.
This eases the the control and flow of data. Although in the proposed works some systems allowed to access read-only copies directly
with Polypheny-DB we always have a single point of entry which can vaguely be compared as the poly-layer acting as a master node
when distributing or even routing queries. Hence Polypheny acts as the master anyway. However since any requests have to pass through the poly-layer
we have full control how and where queries need to be routed to allowing us to selectively route read-operations to outdated and up-to-date stores alike.
This enables Polypheny-DB to take full control how different levels of data freshness are being accessed.

With this abstraction layer on top of the stores we can leverage the DBMS to act as a coordination service allowing us to loosen the eager replications and 
locking mechanisms to be restricted to the primary nodes only. Currently, one has to wait until an update is persisted everywhere and are therefore
dependened on slowest performing store.
To mitigate this behaviour we want to decouple the commonly used update transactions and logically divide it into a total of three separate transactions types
to allow deferred refreshments of objects.
\begin{itemize}
    \item \textbf{Update transaction}: Consequently are write operations that are targeted on primary placements only.
    \item \textbf{Propagation transaction}: Belong to a refresh operation updating the data freshness of an outdated secondary node which is 
    executed automatically by the system.
    \item \textbf{Refresh transaction}: A propagation transaction which is manually triggered by a user to refresh the data on an arbitrary outdated node.
\end{itemize}

Allthough, logically being used differently they are technically executed with the same capabilities and only really separate in terms of locking.
They are rather used as a clear indication on which part of the process is referred.

These changes will also have an impact on the partition distribution constraints. For vertically and horizontally partitioned 
entities this means that all constraints on the number of available column-placements can only be considered for primary update stores. Otherwise, this could harm
the consistency of the system. For nodes labeled as outdated any variation is possible.

\subsection{Update Propagation}
We have several possibilities how to handle and propagate the updates.
Since every write-operation needs to go through Polypheny, we can easily keep track which operations have been applied to the primary server and when 
they need to be applied to the secondaries. Essentially every possible solution needs some form of queue to store updates that still need to be executed 
on secondaries. For correct serializability it is sufficient to store the commit timestamp of the update transaction with each queue item. This imposes a natural
execution order of any item in the queue to be delivered to the secondaries.
We propose the following approaches: \\

\textbf{CDC (Change Data Capture)}\\
We can implement the notion of a shadow table which is filled by trigger on the base table.
As soon as the base table gets modified by an update transaction any changes applied are stored and consequently tracked.
Accompanied by a commit-timestamp its content is then used inside propagation transactions to refresh outdated placements.
Once placements are updated the propagated entries inside the shadow table are deleted. 
This has the advantage that we can utilize a common datastructure in Polypheny out-of-the-box without having to implement any further activities.
It is persisted and available after a downtime which ensures the recoverability of the system.
However since this results is generating several statements that essentially has to traverse the entire system in order to be executed this could lead to 
large overhead in the system which could impact the performance as well as requiring more resources.
Furthermore, since this is an updatable table the implemented locking mechanisms has to be applied as well. This excessive accessing however could result in high 
locking situations and therefore again impact the update time after all.\\

\textbf{Internal structure}\\
Another possibility would be to handle this approach entirely with internal structures.
For example with the implementation of a MOM (Message Oriented Middleware) between the poly-layer and available adapters. The initial update transactions can append 
the changes into a persistent queue. This queue can then be asynchronously queried using a pull-based approach on adapter site to apply all changes necessary for them. \\

\textbf{Internal Partitions} \\
Another propositions would be the usage of background processing together with physical partitions. Although, they were originally intended to serve the horizontal partition 
use case they are internally configured to represent a physical table. Partitions could be extended to be used as general system internals
which are accompanied by an update-timestamp that represents the last time the partition has been updated, this could include the Age-of-Information as well as 
the Age-of-Synchronization. Furthermore, since partitions logically belong to partition groups described in \ref{express} we can easily identify which partitions are considered to be 
outdated or should always be up-to-date. With these information we could even use the existing capabilities of the \emph{Partition Manager} which uses the notion of 
partition-qualifiers to identify required levels of freshness.

For every update-transaction the eager replication is loosend to only consider the primary partitions for updates.
For the refresh operation itself we can utilize the \emph{Data Migrator} to extract the relevant data via an accumulated select-statement on the primary placements.
Additionally, to further decouple the data refreshment a hidden shadow partition can be created for this purpose. In that way writes on the primary copy as well as the 
currently existing outdated placements can still be executed while the outdated placement gets refreshed in the background. Once the data migration process has finished, 
we only need to logically apply a \emph{Refresh-Lock} to ensure the overall consistency. During the short time the outdated-site is locked the old placement is dropped and 
the hidden shadow partition is officially being activated. Since this only really requires one select on the primary site, write-operations can still take place, reducing
locks to a minimum. Even during the time the refresh-lock is active the benefits of the poly-layer comes in to play which enables the system to choose to 
route read-operations to primary servers as well.\\


\textbf{View Materialization}:\\
Along the idea of internal partitions materialization could help reduce the number of statements necessary to create new levels of freshness.
Since materialized views are considered to be snapshots of data objects, anytime a propagation or refresh operation is being executed a new materialized view is 
generated on basis of the up-to-date placement.
This would ommit replication operations entirely hence no bookkeeping of the queued updates would be necessary. The only needed reference would be the new timestamp
to calculate the freshness index.

As with the handling of internal partitions this can also be done entirely in the background. This limits the locking time to a minimum and is therefore only really 
necessary when switching the outdated with a refreshed view.
Allthough, one of the biggest downsides of materialization is the large additional resource consumption on storage, it can be neglected for polystore systems, since they are
inherently distributed and would otherwise store the entire content of the table. Therefore, it would even slightly reduce the data footprint on outdated placements.







\subsection{Refresh strategies}
As already stated above, there are essentially three ways to update a secondary node. 
For the automatic execution of propagation transactions a periodic execution has several downsides hence we propose to schedule
refreshment on the basis of the load on the outdated placements. Therefore, we will extend the adapter of the underlying stores to gather metrics on current workload
average response times in order to enable the poly-layer to decide based on this metrics when it is suitable to carry out a propagation-transaction.


Since it might be possible that a user may consider refreshing a placement manually, we have proposed refresh transactions. With this a user has the possibility to refresh
any replicas which are classified as outdated to a specific freshness level.
\begin{verbatim}
ALTER TABLE dummy REFRESH PLACEMENT ON STORE outdated_store 
UNTIL <TIMESTAMP>;
\end{verbatim}
Without any specification the placements shall be updated to the most recent state of the up-to-date version:
\begin{verbatim}
ALTER TABLE dummy REFRESH PLACEMENT ON STORE outdated_store;
\end{verbatim}

For this operation only freshness levels greater than the current local freshness level can be considered.
Furthermore, this should also provide the possibility to refresh all placements of an object.
\begin{verbatim}
ALTER TABLE dummy REFRESH ALL PLACEMENTS;
\end{verbatim}

Although such refresh-transactions can be executed on any placement, it will have no effect on primaries and simply omit their execution. 




\subsection{ Identify stale data }
\label{stale}

A prerequisite for the automatic execution of propagtion transactions is the identification of stale and outdated placements.
Although a trivial option would be to use the roles described in \ref{roles} and periodically gather all labeled placements, this would not scale much
considering a large amount of tables with at least one additional replica per table.\\

One proposition would be after every update transaction has commited to immediately inform dedicated notification services which will instantly trigger 
a load analysis on stores to be replicated. A sligthly different approach would be a central gossiping service as an adapter extension that gathers store metrics 
and declares them as idle, or loaded. With such a mechanism the notification service which received the information to update stores would not start querying a server
again and can directly utilize the pre-gathered metrics and choose to execute the update or defer it again.\\

Another approach to identify and update stale placements would be the idea to use update-on-read. Everytime a node flaged as outdated is used to serve a 
read-operation the level of freshness can be checked. If identified as outdated this could then trigger any of the propagation transactions proposed in 
\ref{r:strategies}. This would completely omit periodic background scheduling and would shorten processing time.\\
 
However, for both cases in terms of the resulting refresh rate we still have to consider if the change data becomes too large the refreshes tend to take longer.
So countermeasures have to be defined to minimize errors or downtimes.






\section{ Transactional guarantees }
\label{consistency}

To support the overall consistency of the system we have to ensure that all updates are correctly serialized and applied to the system.

Polypheny for one ensures global atomicty by using the two-phase commit (2PC) protocol and for correct isolation treatment
strong strict to phase locking (SS2PL). Currently, all placements are eagerly updated and locked whenever a write-operation is executed.
We need to loosen that constraints to increase update times and still ensure all transactional guarantees. The locking mechanism should therefore 
now only consider primary nodes. In that way we still can utilize secondaries with slightly outdated data for reads.\\

To ensure that the overall correctness of the system is maintained we will restrict the solution to allow freshness related parameters solely
for read-only transactions. For every update-transaction which considers freshness of any kind, consistency cannot be guaranteed since we might read outdated data
and use this data to write into another table. Therefore, we propose to enrich  the transactional context of Polypheny with a flag that states if any read-operation 
considers freshness. If this is the case, the update-transactions needs to be aborted.\\


Another important point to note is the referential integrity of outdated tables. We already ensured that outdated data cannot be used within update-transactions to 
ensure consistency and therefore guarantee correctness. However, for read-only transactions it should still be possible to join any tables while considering 
a desired level of freshness. 
Since it is rather complex and would result in refactoring the core of Polypheny-DBs, we currently refrain from supporting MVCC.
Hence, it might occur that cumulative reads on multiple objects might return incomplete results, since a specified freshness
level can be entirely different on two tables which makes it hard to even compare freshness levels among different objects. However since a user is willing to access 
stale data anyway this is a known risk and thus can be accepted.\\

Finally, as introduced in \ref{replication} the \emph{Refresh-Lock} is a newly introduced lock which holds the same characteristics as a regular lock on an object.
However, it shall only be applied whenever a refresh operation is currently in place. This way the routing mechanism can avoid sending any queries to that placement
for reads or a new refresh operation, which might have been triggered manually by an user.

To ensure the correct execution of refresh operations every placement that is outdated will receive an independent propagation- or refresh-transaction.
The serialization order of the updates to be executed is the commit order of the initial write transaction.
These can also be refreshed and updated independently which not only again reduces the total update time but also eases rollback scenarios.
Otherwise, we might need to define complex countermeasures to undo certain refreshes if one store was already refreshed but another has failed.




\section{ Freshness-aware Read Access }

With the description of \ref{express} how to explicitly express freshness, users have the ability to hint or even guide the routing process to select placements 
based on their desired freshness.\\
Users can choose to specify any tolerated level of freshness. The routing process analyzes this specification and gathers all placements which fulfil the necessary 
requirements by preferring secondary nodes labeled as outdated.
In case no secondary node can fulfil the request a primary placement is used to serve the query since they are not exclusive to receive updates such in other systems,
consequently utilizing all source available to the system.
Since only few systems presented in \ref{r:read} provided this functionality the routing process can be extended to support load balancing. 
With the proposed adapter background analysis the router can observe if any selected placement might be overloaded and therefore chooses to route 
queries to a different available location. \\



For the overall freshness guidance an extension of PolySQL is necessary.
Along the description in \ref{express} users can choose to select any of the specifications to guide the system.
\begin{verbatim}
SELECT * FROM dummy 
[ WITH FRESHNESS [ <TIMESTAMP> | <DELAY> | <PERCENTAGE> ] ];
\end{verbatim}
As an extension we also propose to omit the specifications entirely and only state to the system that any freshness level is acceptable or the system central
configured default, to further speed up queries.



As mentioned in \ref{consistency} since update transactions don't allow any usage of freshness metrics to ensure consistency, solely read-only transactions are allowed.
Hence, for read-operations on outdated nodes and data, locks can be omitted entirely since you will read stale data anyway.
We therefore only have to validate that no refresh-lock is currently in place.







\section{ Policies }

According to the idea, to generally relax consistency or allow a fine grained way of letting data owners decide what kind of consistency shall be desired for their object. 
Since freshness can be considered a trade-off between availability and consistency it is only fair to let users decide which level of consistency to enforce and 
how the freshness should be handled. We therefore propose the notion of policies to guide the system.
Policies are essentially intentions and desired states how the system should behave in various situations. 
The system can apply them when manual or automatic system maintenance is performed.
They shall therefore be introduced for any kind of configurable behaviour to allow any custom tailored behaviour. \\

Policies can be inherented and applied to any kind of object. When applied to a schema all entities inherent that polcies.
However, a different kind of policy with the same type can be applied to an entity overriding the one inherented by the parent.
Policies are about background processing how metadata and constraints on different objects are enforced. 
They provide a lightweight version of UDFs (User-Defined-Functions) to build custom-tailored behaviours into the system.
Other than the central configuration which is used to define core system behaviours. 
Such policies can be defined as:\\


\textbf{Consistency Policies}\\
Provide a notion of tuneable consistency, where users should be able to decide which levels to fulfill.
In such a case an adminsitrator could choose to define how many primary replicas an object should always contain.
This would directly impact the constraints on the table restricting users to remove more placements than defined by that policy.\\


\textbf{Freshness Policies}\\
Can be utilized to define behaviour on freshness related actions. As \cite{fekete:2018} stated it is crucial to define how far a replica can diverge from the true
and up-to-date value before a refresh transaction has to be critically executed.
Additionally, we could use these types of policies to let object owners define how their data shall be identified and consequently updates are propagated.
In such a way the system would stay customizable and would allow any methods discussed in \ref{stale} to be used dependent on the use case.
Considering how refreshes are triggered one policy for example might has chosen to defer a propagation transaction entirely hence it won't try again and
essentially waits for another chance when a new update-transaction is being executed and will trigger the service again. Another policy could suit other use cases better 
and assist by constantly querying the storages perfromance metrics to decide if an update should be executed.\\

Due to the inherent heterogenous nature of the polystore systems itself, use cases may widely vary. Hence, in gerneal there is no need to impose a 
general notion of freshness that is valid for all applications. Some might consider using CDC, while other prefer a partition approach or materialized views.
However, with policies these can all be implemented.\\


\subsection{Policy usage}

Since applications that are being served by polystores are very different to each other, they might have different requirements. 
Therefore, different object types shall be supported.

A policy shall generally be created inside a database.
\begin{verbatim}
CREATE POLICY policy_name as <configuration>;
\end{verbatim}

These policies can then be added to any object.
\begin{verbatim}
ALTER TABLE dummy ADD POLICY policy_name;
\end{verbatim}

Users should always be able to list information on all applied policies on any object.
\begin{verbatim}
SHOW POLICIES ON (DATABASE | SCHEMA | TABLE ) object_name;
\end{verbatim}


Furthermore they should be able to view the content of any policy: 
\begin{verbatim}
DESCRIBE POLICIY policy_name ON (DATABASE | SCHEMA | TABLE ) object_name; 
\end{verbatim}

To complement the idea of policies we also need a central \emph{Policy Manager} which ensures that the specified intentions are ensured.
The manager shall be added as an additional central component and acts as a verification layer whenever meta information on objects will change.

